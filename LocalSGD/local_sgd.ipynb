{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7UrRvO7kOKIcLqnMOb/Rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "beef4b8834324010b7056dfcb147b9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb4ebcf8f3b437ea2240e50056982c5",
              "IPY_MODEL_27d36c433ca64581abe8fdb93b576289",
              "IPY_MODEL_2fc6982638c947f1bfaa2c7a1cda1c74"
            ],
            "layout": "IPY_MODEL_5ed1f15304594b93bbdb2cb76ba37a46"
          }
        },
        "5fb4ebcf8f3b437ea2240e50056982c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42f5684ecc114c67807c8c782cd30685",
            "placeholder": "​",
            "style": "IPY_MODEL_21aa81b5468d4c8294cf1de171e65a8b",
            "value": "LocalSGD Progress: 100%"
          }
        },
        "27d36c433ca64581abe8fdb93b576289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9830c3ced63b4f419ea9cfc518c01173",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cf5f9dc916d4ee7aedc495c13409d17",
            "value": 200
          }
        },
        "2fc6982638c947f1bfaa2c7a1cda1c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1869ff6d0ca5461ea89e43a0516bbdbe",
            "placeholder": "​",
            "style": "IPY_MODEL_63e944061fb94ec2b4f84a5790cd4c2f",
            "value": " 200/200 [04:54&lt;00:00,  2.17s/it, test_acc=29.34%, test_loss=2.7735]"
          }
        },
        "5ed1f15304594b93bbdb2cb76ba37a46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f5684ecc114c67807c8c782cd30685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21aa81b5468d4c8294cf1de171e65a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9830c3ced63b4f419ea9cfc518c01173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf5f9dc916d4ee7aedc495c13409d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1869ff6d0ca5461ea89e43a0516bbdbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e944061fb94ec2b4f84a5790cd4c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zurehma/AML_Project/blob/nicolai/LocalSGD/local_sgd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YU8YrJ9kRGK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228,
          "referenced_widgets": [
            "beef4b8834324010b7056dfcb147b9dd",
            "5fb4ebcf8f3b437ea2240e50056982c5",
            "27d36c433ca64581abe8fdb93b576289",
            "2fc6982638c947f1bfaa2c7a1cda1c74",
            "5ed1f15304594b93bbdb2cb76ba37a46",
            "42f5684ecc114c67807c8c782cd30685",
            "21aa81b5468d4c8294cf1de171e65a8b",
            "9830c3ced63b4f419ea9cfc518c01173",
            "0cf5f9dc916d4ee7aedc495c13409d17",
            "1869ff6d0ca5461ea89e43a0516bbdbe",
            "63e944061fb94ec2b4f84a5790cd4c2f"
          ]
        },
        "id": "EV0rr92biQ66",
        "outputId": "f6e528ef-1a22-495d-b55c-1cf2b95a86e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "Using device: cuda:0\n",
            "==================================================\n",
            "LOCALSGD DISTRIBUTED TRAINING\n",
            "==================================================\n",
            "Clients: 4, Local steps: 10, Rounds: 200\n",
            "Data distribution: IID\n",
            "Created 4 IID shards with ~12500 samples each\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LocalSGD Progress:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beef4b8834324010b7056dfcb147b9dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LocalSGD Results: Final=29.34%, Best=29.40%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10, CIFAR100\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Seeding for reproducibility\n",
        "seed = 2025\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "# data loading\n",
        "def load_data(dataset_name=\"cifar100\", batch_size=128, num_workers=0):\n",
        "    \"\"\"CIFAR-100\"\"\"\n",
        "\n",
        "    train_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                (0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)\n",
        "            ),  # CIFAR-100 mean and std\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    test_transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if dataset_name.lower() == \"cifar100\":\n",
        "        train_dataset = CIFAR100(\n",
        "            root=\"./data\", train=True, download=True, transform=train_transform\n",
        "        )\n",
        "        test_dataset = CIFAR100(\n",
        "            root=\"./data\", train=False, download=True, transform=test_transform\n",
        "        )\n",
        "        num_classes = 100\n",
        "    else:\n",
        "        raise ValueError(f\"Dataset {dataset_name} not supported\")\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader, num_classes, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "# Models\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(ImprovedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 384)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(192, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def create_model(model_name, num_classes=100):\n",
        "    if model_name.lower() == \"improved_cnn\":\n",
        "        return ImprovedCNN(num_classes=num_classes)\n",
        "    elif model_name.lower() == \"lenet5\":\n",
        "        return LeNet5(num_classes=num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in pbar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        pbar.set_postfix({\"loss\": running_loss / total, \"acc\": 100.0 * correct / total})\n",
        "\n",
        "    train_loss = running_loss / total\n",
        "    train_acc = 100.0 * correct / total\n",
        "\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    test_loss = running_loss / total\n",
        "    test_acc = 100.0 * correct / total\n",
        "\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "# Data distribution functions\n",
        "def create_iid_shards(train_dataset, num_clients):\n",
        "    \"\"\"Create IID data shards for clients\"\"\"\n",
        "    indices = list(range(len(train_dataset)))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    shard_size = len(indices) // num_clients\n",
        "    shards = []\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        start_idx = i * shard_size\n",
        "        if i == num_clients - 1:\n",
        "            end_idx = len(indices)\n",
        "        else:\n",
        "            end_idx = start_idx + shard_size\n",
        "\n",
        "        shard_indices = indices[start_idx:end_idx]\n",
        "        shards.append(Subset(train_dataset, shard_indices))\n",
        "\n",
        "    print(f\"Created {num_clients} IID shards with ~{shard_size} samples each\")\n",
        "    return shards\n",
        "\n",
        "\n",
        "def create_non_iid_shards(train_dataset, num_clients, alpha=0.5):\n",
        "    \"\"\"Create non-IID data shards using Dirichlet distribution\"\"\"\n",
        "    if hasattr(train_dataset, \"targets\"):\n",
        "        targets = np.array(train_dataset.targets)\n",
        "    else:\n",
        "        targets = np.array([train_dataset[i][1] for i in range(len(train_dataset))])\n",
        "\n",
        "    num_classes = len(np.unique(targets))\n",
        "\n",
        "    # group indices by class\n",
        "    class_indices = {k: [] for k in range(num_classes)}\n",
        "    for idx, label in enumerate(targets):\n",
        "        class_indices[label].append(idx)\n",
        "\n",
        "    # client indices\n",
        "    client_indices = [[] for _ in range(num_clients)]\n",
        "\n",
        "    # Distribute each class according to Dirichlet distribution\n",
        "    for class_id in range(num_classes):\n",
        "        class_samples = class_indices[class_id]\n",
        "        random.shuffle(class_samples)\n",
        "\n",
        "        # Sample proportions from Dirichlet distribution\n",
        "        proportions = np.random.dirichlet([alpha] * num_clients)\n",
        "\n",
        "        # Distribute samples\n",
        "        start_idx = 0\n",
        "        for client_id in range(num_clients):\n",
        "            num_samples = int(len(class_samples) * proportions[client_id])\n",
        "            if client_id == num_clients - 1:\n",
        "                end_idx = len(class_samples)\n",
        "            else:\n",
        "                end_idx = start_idx + num_samples\n",
        "\n",
        "            client_indices[client_id].extend(class_samples[start_idx:end_idx])\n",
        "            start_idx = end_idx\n",
        "\n",
        "    # Shuffle and create subsets\n",
        "    for indices in client_indices:\n",
        "        random.shuffle(indices)\n",
        "\n",
        "    shards = [Subset(train_dataset, indices) for indices in client_indices]\n",
        "\n",
        "    sizes = [len(shard) for shard in shards]\n",
        "    print(f\"Created {num_clients} non-IID shards (α={alpha}) with sizes: {sizes}\")\n",
        "\n",
        "    return shards\n",
        "\n",
        "\n",
        "# Centralized training\n",
        "def train_centralized_model(\n",
        "    model_name=\"improved_cnn\",\n",
        "    dataset_name=\"cifar100\",\n",
        "    batch_size=64,\n",
        "    epochs=80,\n",
        "    lr=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=4e-4,\n",
        "    lr_scheduler=\"step\",\n",
        "):\n",
        "    \"\"\"Centralized training baseline\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"CENTRALIZED TRAINING\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Load data\n",
        "    train_loader, test_loader, num_classes, _, _ = load_data(\n",
        "        dataset_name=dataset_name, batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = create_model(model_name, num_classes=num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Model: {model_name}, Total parameters: {total_params:,}\")\n",
        "\n",
        "    # loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss for multi-class classification\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay\n",
        "    )  # SGDM optimizer\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    if lr_scheduler == \"step\":\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "            optimizer, milestones=[40, 60], gamma=0.1\n",
        "        )\n",
        "    elif lr_scheduler == \"cosine\":\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    else:\n",
        "        scheduler = None\n",
        "        print(\"No learning rate scheduler used\")\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "    }\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    epoch_pbar = tqdm(range(epochs), desc=\"Centralized Training\")\n",
        "\n",
        "    for epoch in epoch_pbar:\n",
        "        # Training\n",
        "        train_loss, train_acc = train_epoch(\n",
        "            model, train_loader, criterion, optimizer, device\n",
        "        )\n",
        "\n",
        "        # Evaluation\n",
        "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Update best accuracy\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "\n",
        "        # Update history\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"test_loss\"].append(test_loss)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        # Update progress bar\n",
        "        epoch_pbar.set_postfix(\n",
        "            {\n",
        "                \"train_acc\": f\"{train_acc:.2f}%\",\n",
        "                \"test_acc\": f\"{test_acc:.2f}%\",\n",
        "                \"best\": f\"{best_acc:.2f}%\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "    print(f\"\\nCentralized Results: Final={test_acc:.2f}%, Best={best_acc:.2f}%\")\n",
        "\n",
        "    return model, history, best_acc\n",
        "\n",
        "\n",
        "# LocalSGD training\n",
        "def train_localsgd(\n",
        "    model_name=\"improved_cnn\",\n",
        "    dataset_name=\"cifar100\",\n",
        "    num_clients=12,\n",
        "    local_steps=30,\n",
        "    communication_rounds=200,\n",
        "    client_batch_size=64,\n",
        "    lr=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=4e-4,\n",
        "    iid=True,\n",
        "    alpha=0.5,\n",
        "):\n",
        "    \"\"\"LocalSGD distributed training\"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"LOCALSGD DISTRIBUTED TRAINING\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\n",
        "        f\"Clients: {num_clients}, Local steps: {local_steps}, Rounds: {communication_rounds}\"\n",
        "    )\n",
        "    print(f\"Data distribution: {'IID' if iid else f'non-IID (α={alpha})'}\")\n",
        "\n",
        "    # Load data\n",
        "    _, test_loader, num_classes, train_dataset, _ = load_data(\n",
        "        dataset_name=dataset_name, batch_size=128\n",
        "    )\n",
        "\n",
        "    # create data shards\n",
        "    if iid:\n",
        "        shards = create_iid_shards(train_dataset, num_clients)\n",
        "    else:\n",
        "        shards = create_non_iid_shards(train_dataset, num_clients, alpha)\n",
        "\n",
        "    # Create client data loaders\n",
        "    client_loaders = [\n",
        "        DataLoader(shard, batch_size=client_batch_size, shuffle=True, num_workers=0)\n",
        "        for shard in shards\n",
        "    ]\n",
        "\n",
        "    # initialize client models\n",
        "    client_models = [\n",
        "        create_model(model_name, num_classes=num_classes).to(device)\n",
        "        for _ in range(num_clients)\n",
        "    ]\n",
        "\n",
        "    # synchronize initial weights\n",
        "    with torch.no_grad():\n",
        "        for client_model in client_models[1:]:\n",
        "            for target_param, source_param in zip(\n",
        "                client_model.parameters(), client_models[0].parameters()\n",
        "            ):\n",
        "                target_param.data.copy_(source_param.data)\n",
        "\n",
        "    # optimizers\n",
        "    client_optimizers = [\n",
        "        torch.optim.SGD(\n",
        "            model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay\n",
        "        )\n",
        "        for model in client_models\n",
        "    ]\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # metrics\n",
        "    test_accuracies = []\n",
        "    test_losses = []\n",
        "\n",
        "    # LocalSGD main loop\n",
        "    round_pbar = tqdm(range(communication_rounds), desc=\"LocalSGD Progress\")\n",
        "\n",
        "    for round_num in round_pbar:\n",
        "        # Local training phase\n",
        "        for client_id in range(num_clients):\n",
        "            model = client_models[client_id]\n",
        "            optimizer = client_optimizers[client_id]\n",
        "            data_loader = client_loaders[client_id]\n",
        "\n",
        "            model.train()\n",
        "            data_iter = iter(data_loader)\n",
        "\n",
        "            for step in range(local_steps):\n",
        "                try:\n",
        "                    inputs, targets = next(data_iter)\n",
        "                except StopIteration:\n",
        "                    data_iter = iter(data_loader)\n",
        "                    inputs, targets = next(data_iter)\n",
        "\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # Communication phase - model averaging\n",
        "        with torch.no_grad():\n",
        "            # Initialize averaged parameters\n",
        "            averaged_params = []\n",
        "            for param in client_models[0].parameters():\n",
        "                averaged_params.append(torch.zeros_like(param))\n",
        "\n",
        "            # Sum all client parameters\n",
        "            for client_model in client_models:\n",
        "                for avg_param, client_param in zip(\n",
        "                    averaged_params, client_model.parameters()\n",
        "                ):\n",
        "                    avg_param += client_param\n",
        "\n",
        "            # Average the parameters\n",
        "            for avg_param in averaged_params:\n",
        "                avg_param /= num_clients\n",
        "\n",
        "            # Update all client models\n",
        "            for client_model in client_models:\n",
        "                for client_param, avg_param in zip(\n",
        "                    client_model.parameters(), averaged_params\n",
        "                ):\n",
        "                    client_param.data.copy_(avg_param)\n",
        "\n",
        "        # Evaluation\n",
        "        if (round_num + 1) % 5 == 0:  # Evaluate every 5 rounds\n",
        "            global_model = client_models[0]\n",
        "            test_loss, test_acc = evaluate(global_model, test_loader, criterion, device)\n",
        "            test_accuracies.append(test_acc)\n",
        "            test_losses.append(test_loss)\n",
        "\n",
        "            round_pbar.set_postfix(\n",
        "                {\"test_acc\": f\"{test_acc:.2f}%\", \"test_loss\": f\"{test_loss:.4f}\"}\n",
        "            )\n",
        "\n",
        "    final_acc = test_accuracies[-1] if test_accuracies else 0\n",
        "    best_acc = max(test_accuracies) if test_accuracies else 0\n",
        "\n",
        "    print(f\"\\nLocalSGD Results: Final={final_acc:.2f}%, Best={best_acc:.2f}%\")\n",
        "\n",
        "    history = {\"test_accuracies\": test_accuracies, \"test_losses\": test_losses}\n",
        "\n",
        "    return client_models[0], history, best_acc\n",
        "\n",
        "\n",
        "def main(mode=\"centralized\", **kwargs):\n",
        "    \"\"\"Main function to run different training modes.\n",
        "\n",
        "    Modes:\n",
        "    - \"centralized\": Run only centralized training\n",
        "    - \"localsgd\": Run only LocalSGD training\n",
        "    \"\"\"\n",
        "\n",
        "    if mode == \"centralized\":\n",
        "        model, history, best_acc = train_centralized_model(**kwargs)\n",
        "        return model, history\n",
        "\n",
        "    elif mode == \"localsgd\":\n",
        "        model, history, best_acc = train_localsgd(**kwargs)\n",
        "        return model, history\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}. Use 'centralized'\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(\n",
        "        mode=\"localsgd\",\n",
        "        model_name=\"improved_cnn\",\n",
        "        dataset_name=\"cifar100\",\n",
        "        num_clients=4,\n",
        "        local_steps=10,\n",
        "        communication_rounds=200,\n",
        "        client_batch_size=64,\n",
        "        lr=0.01,\n",
        "        momentum=0.9,\n",
        "        weight_decay=4e-4,\n",
        "    )\n"
      ]
    }
  ]
}